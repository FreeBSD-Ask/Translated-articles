# ä½¿ç”¨ Pacemaker ä¸ Corosync æ„å»º FreeBSD é›†ç¾¤

- åŸæ–‡ï¼š[FreeBSD Cluster with Pacemaker and Corosync](https://vermaden.wordpress.com/2020/09/03/freebsd-cluster-with-pacemaker-and-corosync/)
- ä½œè€…ï¼šğšŸğšğš›ğš–ğšŠğšğšğš—
- 2020/09/03

æˆ‘ä¸€ç›´å¾ˆæƒ³æ‰¾åˆ°é€‚åˆ FreeBSD ç³»ç»Ÿçš„â€œæ­£ç»Ÿâ€é›†ç¾¤è½¯ä»¶ã€‚æœ€è¿‘æˆ‘æœ‰æœºä¼šåœ¨ Linux ç³»ç»Ÿä¸Šè¿è¡Œå‡ ä¸ªåŸºäº Pacemaker/Corosync çš„é›†ç¾¤ã€‚æˆ‘å¼€å§‹æ€è€ƒå¦‚ä½•åœ¨ FreeBSD ä¸Šå®ç°ç±»ä¼¼çš„é«˜å¯ç”¨æ€§è§£å†³æ–¹æ¡ˆï¼Œå½“æˆ‘å‘ç° Pacemaker å’Œ Corosync å·¥å…·åœ¨ FreeBSD Ports å’ŒåŒ…ä¸­åˆ†åˆ«å¯ä»¥é€šè¿‡ **net/pacemaker2** å’Œ **net/corosync2** è·å¾—æ—¶ï¼Œæˆ‘çœŸçš„éå¸¸éœ‡æƒŠã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†æ£€æŸ¥ Pacemaker å’Œ Corosync é›†ç¾¤åœ¨ FreeBSD ä¸Šçš„è¿è¡Œæƒ…å†µã€‚

![pacemaker](https://vermaden.wordpress.com/wp-content/uploads/2020/09/pacemaker.png?w=960)

å…³äºé›†ç¾¤ï¼Œæœ‰å¾ˆå¤šå®šä¹‰ã€‚æˆ‘æœ€å–œæ¬¢çš„ä¸€ä¸ªå®šä¹‰æ˜¯ï¼šé›†ç¾¤æ˜¯å³ä½¿å¤±å»å…¶ä¸­ä¸€ä¸ªèŠ‚ç‚¹ä»ä¿æŒå†—ä½™çš„ç³»ç»Ÿï¼ˆä»ç„¶æ˜¯é›†ç¾¤ï¼‰ã€‚è¿™æ„å‘³ç€æ ¹æ®è¿™ä¸ªå®šä¹‰ï¼Œé›†ç¾¤çš„æœ€å°‘èŠ‚ç‚¹æ•°æ˜¯ 3 ä¸ªã€‚ä¸¤èŠ‚ç‚¹é›†ç¾¤å­˜åœ¨è¾ƒå¤§é—®é¢˜ï¼Œå› ä¸ºå®ƒä»¬æœ€å®¹æ˜“å‡ºç°è„‘è£‚é—®é¢˜ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨ä¸¤èŠ‚ç‚¹é›†ç¾¤ä¸­ï¼Œé€šå¸¸ä¼šæ·»åŠ é¢å¤–çš„è®¾å¤‡æˆ–ç³»ç»Ÿï¼Œä»¥ç¡®ä¿è„‘è£‚ä¸ä¼šå‘ç”Ÿã€‚ä¾‹å¦‚ï¼Œå¯ä»¥æ·»åŠ ç¬¬ä¸‰ä¸ªèŠ‚ç‚¹ï¼Œä¸æä¾›ä»»ä½•èµ„æºæˆ–æœåŠ¡ï¼Œä»…ä½œä¸ºâ€œè§è¯è€…â€è§’è‰²ã€‚å¦ä¸€ç§æ–¹å¼æ˜¯æ·»åŠ å…±äº«ç£ç›˜èµ„æºï¼Œå…¶ä½œç”¨ç›¸åŒï¼Œé€šå¸¸æ˜¯ä½¿ç”¨ SCSI-3 æŒä¹…ä¿ç•™æœºåˆ¶çš„åŸå§‹å·ã€‚

# å®éªŒå®¤æ­å»º

å’Œä»¥å¾€ä¸€æ ·ï¼Œæ•´ä¸ªå®éªŒå°†åŸºäº VirtualBoxï¼Œå¹¶ç”± 3 å°ä¸»æœºç»„æˆã€‚ä¸ºäº†ä¸åˆ›å»º 3 ä¸ªç›¸åŒçš„ FreeBSD å®‰è£…ï¼Œæˆ‘ä½¿ç”¨äº† FreeBSD é¡¹ç›®ç›´æ¥æä¾›çš„ 12.1-RELEASE è™šæ‹Ÿæœºé•œåƒï¼š

* [https://download.freebsd.org/ftp/releases/VM-IMAGES/12.1-RELEASE/](https://download.freebsd.org/ftp/releases/VM-IMAGES/12.1-RELEASE/)

æœ‰å‡ ç§æ ¼å¼å¯é€‰ â€“ **qcow2**/**raw**/**vhd**/**vmdk** â€“ å› ä¸ºæˆ‘å°†ä½¿ç”¨ VirtualBoxï¼Œæ‰€ä»¥é€‰æ‹©äº† [VMDK](https://download.freebsd.org/ftp/releases/VM-IMAGES/12.1-RELEASE/amd64/Latest/FreeBSD-12.1-RELEASE-amd64.vmdk.xz) æ ¼å¼ã€‚

ä¸‹é¢æ˜¯ GlusterFS é›†ç¾¤çš„ä¸»æœºåˆ—è¡¨ï¼š

* 10.0.10.111 node1
* 10.0.10.112 node2
* 10.0.10.113 node3

æ¯ä¸ª VirtualBox çš„ FreeBSD è™šæ‹Ÿæœºå‡ä¸ºé»˜è®¤é…ç½®ï¼ˆå¦‚ VirtualBox å‘å¯¼æ‰€å»ºè®®ï¼‰ï¼Œå†…å­˜ä¸º 512 MBï¼Œç½‘ç»œæ¨¡å¼ä¸º *NAT Network*ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![machine](https://vermaden.wordpress.com/wp-content/uploads/2020/09/machine-1.jpg?w=960)

ä¸‹é¢æ˜¯ VirtualBox ä¸Š *NAT Network* çš„é…ç½®ã€‚

![nat-network-01](https://vermaden.wordpress.com/wp-content/uploads/2020/09/nat-network-01.jpg?w=960)

![nat-network-02](https://vermaden.wordpress.com/wp-content/uploads/2020/09/nat-network-02.jpg?w=960)

åœ¨å°è¯•è¿æ¥ FreeBSD ä¸»æœºä¹‹å‰ï¼Œéœ€è¦åœ¨æ¯å°è™šæ‹Ÿæœºå†…è¿›è¡Œæœ€å°ç½‘ç»œé…ç½®ã€‚æ¯å° FreeBSD ä¸»æœºå°†å…·æœ‰å¦‚ä¸‹ç¤ºä¾‹çš„æœ€å° **/etc/rc.conf** æ–‡ä»¶ï¼ˆä»¥ **node1** ä¸ºä¾‹ï¼‰ã€‚

```sh
root@node1:~ # cat /etc/rc.conf
hostname=node1
ifconfig_em0="inet 10.0.10.111/24 up"
defaultrouter=10.0.10.1
sshd_enable=YES
```

ä¸ºäº†æ­å»ºå®éªŒç¯å¢ƒï¼Œæˆ‘ä»¬éœ€è¦å…è®¸ **root** ç™»å½•è¿™äº› FreeBSD ä¸»æœºï¼Œåœ¨ **/etc/ssh/sshd_config** æ–‡ä»¶ä¸­è®¾ç½® **PermitRootLogin yes**ã€‚æ›´æ”¹åï¼Œè¿˜éœ€è¦é‡å¯ **sshd(8)** æœåŠ¡ã€‚

```sh
root@node1:~ # grep PermitRootLogin /etc/ssh/sshd_config
PermitRootLogin yes

root@node1:~ # service sshd restart
```

é€šè¿‡ä½¿ç”¨å¸¦æœ‰ *ç«¯å£è½¬å‘* çš„ NAT Networkï¼ŒFreeBSD ä¸»æœºå°†å¯ä»¥é€šè¿‡æœ¬åœ°ä¸»æœºç«¯å£è®¿é—®ã€‚ä¾‹å¦‚ï¼Œ**node1** å¯ä»¥é€šè¿‡ç«¯å£ **2211** è®¿é—®ï¼Œ**node2** å¯ä»¥é€šè¿‡ç«¯å£ **2212** è®¿é—®ï¼Œä¾æ­¤ç±»æ¨ã€‚å¦‚ä¸‹ **sockstat** å·¥å…·è¾“å‡ºæ‰€ç¤ºã€‚


![nat-network-03-sockstat](https://vermaden.wordpress.com/wp-content/uploads/2020/09/nat-network-03-sockstat.jpg?w=960)

![nat-network-04-ssh](https://vermaden.wordpress.com/wp-content/uploads/2020/09/nat-network-04-ssh.jpg?w=960)

è¦ä» VirtualBox ä¸»æœºç³»ç»Ÿè¿æ¥åˆ°è¿™æ ·çš„è™šæ‹Ÿæœºï¼Œéœ€è¦ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼š

```
vboxhost % ssh -l root localhost -p 2211
```

# è½¯ä»¶åŒ…

ç°åœ¨æˆ‘ä»¬å·²ç»å¯ä»¥é€šè¿‡ **ssh(1)** è¿æ¥ï¼Œéœ€è¦æ·»åŠ æ‰€éœ€çš„è½¯ä»¶åŒ…ã€‚ä¸ºäº†è®©æˆ‘ä»¬çš„è™šæ‹Ÿæœºèƒ½å¤Ÿè§£æ DNS æŸ¥è¯¢ï¼Œè¿˜éœ€è¦åšæœ€åä¸€ä»¶äº‹ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å°†åˆ‡æ¢ **pkg(8)** è½¯ä»¶åŒ…åˆ° â€œquarterlyâ€ åˆ†æ”¯ã€‚

```
root@node1:~ # echo 'nameserver 1.1.1.1' > /etc/resolv.conf
root@node1:~ # sed -i '' s/quarterly/latest/g /etc/pkg/FreeBSD.conf
```

è¯·è®°å¾—åœ¨ **node2** å’Œ **node3** ç³»ç»Ÿä¸Šé‡å¤æ‰§è¡Œä¸Šè¿°ä¸¤æ¡å‘½ä»¤ã€‚

ç°åœ¨æˆ‘ä»¬å°†å®‰è£… Pacemaker å’Œ Corosync è½¯ä»¶åŒ…ã€‚

```
root@node1:~ # pkg install pacemaker2 corosync2 crmsh

root@node2:~ # pkg install pacemaker2 corosync2 crmsh

root@node3:~ # pkg install pacemaker2 corosync2 crmsh
```

ä¸‹é¢æ˜¯ **pacemaker2** å’Œ **corosync2** çš„ä¸€äº›éœ€è¦æˆ‘ä»¬å¤„ç†çš„ä¿¡æ¯ã€‚

```sh
Message from pacemaker2-2.0.4:

--
For correct operation, maximum socket buffer size must be tuned
by performing the following command as root :

# sysctl kern.ipc.maxsockbuf=18874368

To preserve this setting across reboots, append the following
to /etc/sysctl.conf :

kern.ipc.maxsockbuf=18874368

======================================================================

Message from corosync2-2.4.5_1:

--
For correct operation, maximum socket buffer size must be tuned
by performing the following command as root :

# sysctl kern.ipc.maxsockbuf=18874368

To preserve this setting across reboots, append the following
to /etc/sysctl.conf :

kern.ipc.maxsockbuf=18874368
```

æˆ‘ä»¬éœ€è¦ä¿®æ”¹ **kern.ipc.maxsockbuf** å‚æ•°ã€‚é‚£å°±å¼€å§‹ä¿®æ”¹å§ã€‚

```sh
root@node1:~ # echo 'kern.ipc.maxsockbuf=18874368' >> /etc/sysctl.conf
root@node1:~ # service sysctl restart

root@node2:~ # echo 'kern.ipc.maxsockbuf=18874368' >> /etc/sysctl.conf
root@node2:~ # service sysctl restart

root@node3:~ # echo 'kern.ipc.maxsockbuf=18874368' >> /etc/sysctl.conf
root@node3:~ # service sysctl restart
```

æˆ‘ä»¬æ¥æŸ¥çœ‹è¿™äº›è½¯ä»¶åŒ…éƒ½åŒ…å«äº†å“ªäº›å¯æ‰§è¡Œæ–‡ä»¶ã€‚

```sh
root@node1:~ # pkg info -l pacemaker2 | grep bin
        /usr/local/sbin/attrd_updater
        /usr/local/sbin/cibadmin
        /usr/local/sbin/crm_attribute
        /usr/local/sbin/crm_diff
        /usr/local/sbin/crm_error
        /usr/local/sbin/crm_failcount
        /usr/local/sbin/crm_master
        /usr/local/sbin/crm_mon
        /usr/local/sbin/crm_node
        /usr/local/sbin/crm_report
        /usr/local/sbin/crm_resource
        /usr/local/sbin/crm_rule
        /usr/local/sbin/crm_shadow
        /usr/local/sbin/crm_simulate
        /usr/local/sbin/crm_standby
        /usr/local/sbin/crm_ticket
        /usr/local/sbin/crm_verify
        /usr/local/sbin/crmadmin
        /usr/local/sbin/fence_legacy
        /usr/local/sbin/iso8601
        /usr/local/sbin/pacemaker-remoted
        /usr/local/sbin/pacemaker_remoted
        /usr/local/sbin/pacemakerd
        /usr/local/sbin/stonith_admin

root@node1:~ # pkg info -l corosync2 | grep bin
        /usr/local/bin/corosync-blackbox
        /usr/local/sbin/corosync
        /usr/local/sbin/corosync-cfgtool
        /usr/local/sbin/corosync-cmapctl
        /usr/local/sbin/corosync-cpgtool
        /usr/local/sbin/corosync-keygen
        /usr/local/sbin/corosync-notifyd
        /usr/local/sbin/corosync-quorumtool

root@node1:~ # pkg info -l crmsh | grep bin
        /usr/local/bin/crm
```

# é›†ç¾¤åˆå§‹åŒ–

ç°åœ¨æˆ‘ä»¬å°†åˆå§‹åŒ– FreeBSD é›†ç¾¤ã€‚

é¦–å…ˆéœ€è¦ç¡®ä¿å„èŠ‚ç‚¹çš„åç§°å¯ä»¥é€šè¿‡ DNS è§£æã€‚

```sh
root@node1:~ # tail -3 /etc/hosts

10.0.10.111 node1
10.0.10.112 node2
10.0.10.113 node3

root@node2:~ # tail -3 /etc/hosts

10.0.10.111 node1
10.0.10.112 node2
10.0.10.113 node3

root@node3:~ # tail -3 /etc/hosts

10.0.10.111 node1
10.0.10.112 node2
10.0.10.113 node3
```

ç°åœ¨æˆ‘ä»¬å°†ç”Ÿæˆ Corosync å¯†é’¥ã€‚

```sh
root@node1:~ # corosync-keygen
Corosync Cluster Engine Authentication key generator.
Gathering 1024 bits for key from /dev/random.
Press keys on your keyboard to generate entropy.
Writing corosync key to /usr/local/etc/corosync/authkey.

root@node1:~ # echo $?
0

root@node1:~ # ls -l /usr/local/etc/corosync/authkey
-r--------  1 root  wheel  128 Sep  2 20:37 /usr/local/etc/corosync/authkey
```

ç°åœ¨æ˜¯ Corosync é…ç½®æ–‡ä»¶çš„éƒ¨åˆ†ã€‚å½“ç„¶ï¼Œè½¯ä»¶åŒ…ç»´æŠ¤è€…å·²ç»æä¾›äº†ä¸€äº›ç¤ºä¾‹ã€‚

```sh
root@node1:~ # pkg info -l corosync2 | grep example
        /usr/local/etc/corosync/corosync.conf.example
        /usr/local/etc/corosync/corosync.conf.example.udpu
```

æˆ‘ä»¬å°†ä½¿ç”¨ç¬¬äºŒä¸ªç¤ºä¾‹ä½œä¸ºé…ç½®çš„åŸºç¡€ã€‚

```sh
root@node1:~ # cp /usr/local/etc/corosync/corosync.conf.example.udpu /usr/local/etc/corosync/corosync.conf

root@node1:~ # vi /usr/local/etc/corosync/corosync.conf
               /* LOTS OF EDITS HERE */

root@node1:~ # cat /usr/local/etc/corosync/corosync.conf

totem {
  version: 2
  crypto_cipher: aes256
  crypto_hash: sha256
  transport: udpu

  interface {
    ringnumber: 0
    bindnetaddr: 10.0.10.0
    mcastport: 5405
    ttl: 1
  }
}

logging {
  fileline: off
  to_logfile: yes
  to_syslog: no
  logfile: /var/log/cluster/corosync.log
  debug: off
  timestamp: on

  logger_subsys {
    subsys: QUORUM
    debug: off
  }
}

nodelist {

  node {
    ring0_addr: 10.0.10.111
    nodeid: 1
  }

  node {
    ring0_addr: 10.0.10.112
    nodeid: 2
  }

  node {
    ring0_addr: 10.0.10.113
    nodeid: 3
  }

}

quorum {
  provider: corosync_votequorum
  expected_votes: 2
}
```

ç°åœ¨æˆ‘ä»¬éœ€è¦å°† Corosync å¯†é’¥å’Œé…ç½®æ–‡ä»¶åˆ†å‘åˆ°é›†ç¾¤ä¸­çš„å„ä¸ªèŠ‚ç‚¹ã€‚

å¯ä»¥ä½¿ç”¨ä¸€äº›ä¸“é—¨ä¸ºæ­¤åˆ›å»ºçš„ç®€å•å·¥å…·ï¼Œä¾‹å¦‚ net/csync2 é›†ç¾¤åŒæ­¥å·¥å…·ï¼Œä½†ä¼ ç»Ÿçš„ net/rsync ä¹ŸåŒæ ·å¯ç”¨ã€‚

```sh
root@node1:~ # pkg install -y rsync

root@node1:~ # rsync -av /usr/local/etc/corosync/ node2:/usr/local/etc/corosync/
The authenticity of host 'node2 (10.0.10.112)' can't be established.
ECDSA key fingerprint is SHA256:/ZDmln7GKi6n0kbad73TIrajPjGfQqJJX+ReSf3NMvc.
No matching host key fingerprint found in DNS.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'node2' (ECDSA) to the list of known hosts.
Password for root@node2:
sending incremental file list
./
authkey
corosync.conf
service.d/
uidgid.d/

sent 1,100 bytes  received 69 bytes  259.78 bytes/sec
total size is 4,398  speedup is 3.76

root@node1:~ # rsync -av /usr/local/etc/corosync/ node3:/usr/local/etc/corosync/
The authenticity of host 'node2 (10.0.10.112)' can't be established.
ECDSA key fingerprint is SHA256:/ZDmln7GKi6n0kbad73TIrajPjGfQqJJX+ReSf3NMvc.
No matching host key fingerprint found in DNS.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'node3' (ECDSA) to the list of known hosts.
Password for root@node3:
sending incremental file list
./
authkey
corosync.conf
service.d/
uidgid.d/

sent 1,100 bytes  received 69 bytes  259.78 bytes/sec
total size is 4,398  speedup is 3.76
```

ç°åœ¨æˆ‘ä»¬æ¥æ£€æŸ¥å®ƒä»¬æ˜¯å¦ä¸€è‡´ã€‚

```sh
root@node1:~ # cksum /usr/local/etc/corosync/{authkey,corosync.conf}
2277171666 128 /usr/local/etc/corosync/authkey
1728717329 622 /usr/local/etc/corosync/corosync.conf

root@node2:~ # cksum /usr/local/etc/corosync/{authkey,corosync.conf}
2277171666 128 /usr/local/etc/corosync/authkey
1728717329 622 /usr/local/etc/corosync/corosync.conf

root@node3:~ # cksum /usr/local/etc/corosync/{authkey,corosync.conf}
2277171666 128 /usr/local/etc/corosync/authkey
1728717329 622 /usr/local/etc/corosync/corosync.conf
```

ä¸€è‡´ã€‚

ç°åœ¨æˆ‘ä»¬å¯ä»¥åœ¨ **/etc/rc.conf** æ–‡ä»¶ä¸­æ·»åŠ  **corosync_enable=YES** å’Œ **pacemaker_enable=YES**ã€‚

```sh
root@node1:~ # sysrc corosync_enable=YES
corosync_enable:  -> YES

root@node1:~ # sysrc pacemaker_enable=YES
pacemaker_enable:  -> YES

root@node2:~ # sysrc corosync_enable=YES
corosync_enable:  -> YES

root@node2:~ # sysrc pacemaker_enable=YES
pacemaker_enable:  -> YES

root@node3:~ # sysrc corosync_enable=YES
corosync_enable:  -> YES

root@node3:~ # sysrc pacemaker_enable=YES
pacemaker_enable:  -> YES
```

é‚£å°±å¯åŠ¨è¿™äº›æœåŠ¡å§ã€‚

```sh
root@node1:~ # service corosync start
Starting corosync.
Sep 02 20:55:35 notice  [MAIN  ] Corosync Cluster Engine ('2.4.5'): started and ready to provide service.
Sep 02 20:55:35 info    [MAIN  ] Corosync built-in features:
Sep 02 20:55:35 warning [MAIN  ] interface section bindnetaddr is used together with nodelist. Nodelist one is going to be used.
Sep 02 20:55:35 warning [MAIN  ] Please migrate config file to nodelist.

root@node1:~ # ps aux | grep corosync
root  1695   0.0  7.9 38340 38516  -  S    20:55    0:00.40 /usr/local/sbin/corosync
root  1699   0.0  0.1   524   336  0  R+   20:57    0:00.00 grep corosync
```

åœ¨ **node2** å’Œ **node3** ç³»ç»Ÿä¸Šä¹Ÿæ‰§è¡ŒåŒæ ·æ“ä½œã€‚

ç”±äº Pacemaker è¿˜æœªè¿è¡Œï¼Œå› æ­¤æ“ä½œä¼šå¤±è´¥ã€‚

```sh
root@node1:~ # crm status
Could not connect to the CIB: Socket is not connected
crm_mon: Error: cluster is not available on this node
ERROR: status: crm_mon (rc=102):
```

ç°åœ¨æˆ‘ä»¬å°†å¯åŠ¨å®ƒã€‚

```sh
root@node1:~ # service pacemaker start
Starting pacemaker.

root@node2:~ # service pacemaker start
Starting pacemaker.

root@node3:~ # service pacemaker start
Starting pacemaker.
```

éœ€è¦ç»™å®ƒä¸€äº›å¯åŠ¨æ—¶é—´ï¼Œå› ä¸ºå¦‚æœä½ ç«‹å³æ‰§è¡Œ **crm status** å‘½ä»¤ï¼Œä¼šçœ‹åˆ°å¦‚ä¸‹æ‰€ç¤ºçš„ **0 nodes configured** æ¶ˆæ¯ã€‚

```sh
root@node1:~ # crm status
Cluster Summary:
  * Stack: unknown
  * Current DC: NONE
  * Last updated: Wed Sep  2 20:58:51 2020
  * Last change:  
  * 0 nodes configured
  * 0 resource instances configured


Full List of Resources:
  * No resources
```

â€¦â€¦ä½†è¿‡ä¸€ä¼šå„¿ï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½ä¼šè¢«æ£€æµ‹åˆ°ï¼Œä¸€åˆ‡æŒ‰é¢„æœŸæ­£å¸¸å·¥ä½œã€‚

```sh
root@node1:~ # crm status
Cluster Summary:
  * Stack: corosync
  * Current DC: node2 (version 2.0.4-2deceaa3ae) - partition with quorum
  * Last updated: Wed Sep  2 21:02:49 2020
  * Last change:  Wed Sep  2 20:59:00 2020 by hacluster via crmd on node2
  * 3 nodes configured
  * 0 resource instances configured

Node List:
  * Online: [ node1 node2 node3 ]

Full List of Resources:
  * No resources
```

Pacemaker è¿è¡Œæ­£å¸¸ã€‚

```sh
root@node1:~ # ps aux | grep pacemaker
root      1716   0.0  0.5 10844   2396  -  Is   20:58     0:00.00 daemon: /usr/local/sbin/pacemakerd[1717] (daemon)
root      1717   0.0  5.2 49264  25284  -  S    20:58     0:00.27 /usr/local/sbin/pacemakerd
hacluster 1718   0.0  6.1 48736  29708  -  Ss   20:58     0:00.75 /usr/local/libexec/pacemaker/pacemaker-based
root      1719   0.0  4.5 40628  21984  -  Ss   20:58     0:00.28 /usr/local/libexec/pacemaker/pacemaker-fenced
root      1720   0.0  2.8 25204  13688  -  Ss   20:58     0:00.20 /usr/local/libexec/pacemaker/pacemaker-execd
hacluster 1721   0.0  3.9 38148  19100  -  Ss   20:58     0:00.25 /usr/local/libexec/pacemaker/pacemaker-attrd
hacluster 1722   0.0  2.9 25460  13864  -  Ss   20:58     0:00.17 /usr/local/libexec/pacemaker/pacemaker-schedulerd
hacluster 1723   0.0  5.4 49304  26300  -  Ss   20:58     0:00.41 /usr/local/libexec/pacemaker/pacemaker-controld
root      1889   0.0  0.6 11348   2728  0  S+   21:56     0:00.00 grep pacemaker
```

æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ Corosync å¦‚ä½•è¯†åˆ«å…¶æˆå‘˜ã€‚

```sh
root@node1:~ # corosync-cmapctl | grep members
runtime.totem.pg.mrp.srp.members.1.config_version (u64) = 0
runtime.totem.pg.mrp.srp.members.1.ip (str) = r(0) ip(10.0.10.111) 
runtime.totem.pg.mrp.srp.members.1.join_count (u32) = 1
runtime.totem.pg.mrp.srp.members.1.status (str) = joined
runtime.totem.pg.mrp.srp.members.2.config_version (u64) = 0
runtime.totem.pg.mrp.srp.members.2.ip (str) = r(0) ip(10.0.10.112) 
runtime.totem.pg.mrp.srp.members.2.join_count (u32) = 1
runtime.totem.pg.mrp.srp.members.2.status (str) = joined
runtime.totem.pg.mrp.srp.members.3.config_version (u64) = 0
runtime.totem.pg.mrp.srp.members.3.ip (str) = r(0) ip(10.0.10.113) 
runtime.totem.pg.mrp.srp.members.3.join_count (u32) = 1
runtime.totem.pg.mrp.srp.members.3.status (str) = joined
```

â€¦â€¦æˆ–è€…æŸ¥çœ‹ quorum ä¿¡æ¯ã€‚

```sh
root@node1:~ # corosync-quorumtool
Quorum information
------------------
Date:             Wed Sep  2 21:00:38 2020
Quorum provider:  corosync_votequorum
Nodes:            3
Node ID:          1
Ring ID:          1/12
Quorate:          Yes

Votequorum information
----------------------
Expected votes:   3
Highest expected: 3
Total votes:      3
Quorum:           2  
Flags:            Quorate 

Membership information
----------------------
    Nodeid      Votes Name
         1          1 10.0.10.111 (local)
         2          1 10.0.10.112
         3          1 10.0.10.113
```

Corosync æ—¥å¿—æ–‡ä»¶ä¸­å……æ»¡äº†ä»¥ä¸‹ä¿¡æ¯ã€‚

```sh
root@node1:~ # cat /var/log/cluster/corosync.log
Sep 02 20:55:35 [1694] node1 corosync notice  [MAIN  ] Corosync Cluster Engine ('2.4.5'): started and ready to provide service.
Sep 02 20:55:35 [1694] node1 corosync info    [MAIN  ] Corosync built-in features:
Sep 02 20:55:35 [1694] node1 corosync warning [MAIN  ] interface section bindnetaddr is used together with nodelist. Nodelist one is going to be used.
Sep 02 20:55:35 [1694] node1 corosync warning [MAIN  ] Please migrate config file to nodelist.
Sep 02 20:55:35 [1694] node1 corosync notice  [TOTEM ] Initializing transport (UDP/IP Unicast).
Sep 02 20:55:35 [1694] node1 corosync notice  [TOTEM ] Initializing transmit/receive security (NSS) crypto: aes256 hash: sha256
Sep 02 20:55:35 [1694] node1 corosync notice  [TOTEM ] The network interface [10.0.10.111] is now up.
Sep 02 20:55:35 [1694] node1 corosync notice  [SERV  ] Service engine loaded: corosync configuration map access [0]
Sep 02 20:55:35 [1694] node1 corosync info    [QB    ] server name: cmap
Sep 02 20:55:35 [1694] node1 corosync notice  [SERV  ] Service engine loaded: corosync configuration service [1]
Sep 02 20:55:35 [1694] node1 corosync info    [QB    ] server name: cfg
Sep 02 20:55:35 [1694] node1 corosync notice  [SERV  ] Service engine loaded: corosync cluster closed process group service v1.01 [2]
Sep 02 20:55:35 [1694] node1 corosync info    [QB    ] server name: cpg
Sep 02 20:55:35 [1694] node1 corosync notice  [SERV  ] Service engine loaded: corosync profile loading service [4]
Sep 02 20:55:35 [1694] node1 corosync notice  [QUORUM] Using quorum provider corosync_votequorum
Sep 02 20:55:35 [1694] node1 corosync notice  [SERV  ] Service engine loaded: corosync vote quorum service v1.0 [5]
Sep 02 20:55:35 [1694] node1 corosync info    [QB    ] server name: votequorum
Sep 02 20:55:35 [1694] node1 corosync notice  [SERV  ] Service engine loaded: corosync cluster quorum service v0.1 [3]
Sep 02 20:55:35 [1694] node1 corosync info    [QB    ] server name: quorum
Sep 02 20:55:35 [1694] node1 corosync notice  [TOTEM ] adding new UDPU member {10.0.10.111}
Sep 02 20:55:35 [1694] node1 corosync notice  [TOTEM ] adding new UDPU member {10.0.10.112}
Sep 02 20:55:35 [1694] node1 corosync notice  [TOTEM ] adding new UDPU member {10.0.10.113}
Sep 02 20:55:35 [1694] node1 corosync notice  [TOTEM ] A new membership (10.0.10.111:4) was formed. Members joined: 1
Sep 02 20:55:35 [1694] node1 corosync warning [CPG   ] downlist left_list: 0 received
Sep 02 20:55:35 [1694] node1 corosync notice  [QUORUM] Members[1]: 1
Sep 02 20:55:35 [1694] node1 corosync notice  [MAIN  ] Completed service synchronization, ready to provide service.
Sep 02 20:58:14 [1694] node1 corosync notice  [TOTEM ] A new membership (10.0.10.111:8) was formed. Members joined: 2
Sep 02 20:58:14 [1694] node1 corosync warning [CPG   ] downlist left_list: 0 received
Sep 02 20:58:14 [1694] node1 corosync warning [CPG   ] downlist left_list: 0 received
Sep 02 20:58:14 [1694] node1 corosync notice  [QUORUM] This node is within the primary component and will provide service.
Sep 02 20:58:14 [1694] node1 corosync notice  [QUORUM] Members[2]: 1 2
Sep 02 20:58:14 [1694] node1 corosync notice  [MAIN  ] Completed service synchronization, ready to provide service.
Sep 02 20:58:19 [1694] node1 corosync notice  [TOTEM ] A new membership (10.0.10.111:12) was formed. Members joined: 3
Sep 02 20:58:19 [1694] node1 corosync warning [CPG   ] downlist left_list: 0 received
Sep 02 20:58:19 [1694] node1 corosync warning [CPG   ] downlist left_list: 0 received
Sep 02 20:58:19 [1694] node1 corosync warning [CPG   ] downlist left_list: 0 received
Sep 02 20:58:19 [1694] node1 corosync notice  [QUORUM] Members[3]: 1 2 3
Sep 02 20:58:19 [1694] node1 corosync notice  [MAIN  ] Completed service synchronization, ready to provide service.
```

é…ç½®å¦‚ä¸‹ã€‚

```sh
root@node1:~ # crm configure show
node 1: node1
node 2: node2
node 3: node3
property cib-bootstrap-options: \
        have-watchdog=false \
        dc-version=2.0.4-2deceaa3ae \
        cluster-infrastructure=corosync
```

ç”±äºæˆ‘ä»¬ä¸ä¼šé…ç½® STONITH æœºåˆ¶ï¼Œå› æ­¤å°†å…¶ç¦ç”¨ã€‚

```sh
root@node1:~ # crm configure property stonith-enabled=false
```

ç¦ç”¨ STONITH åçš„æ–°é…ç½®ã€‚

```sh
root@node1:~ # crm configure show
node 1: node1
node 2: node2
node 3: node3
property cib-bootstrap-options: \
        have-watchdog=false \
        dc-version=2.0.4-2deceaa3ae \
        cluster-infrastructure=corosync \
        stonith-enabled=false
```

STONITH é…ç½®è¶…å‡ºäº†æœ¬æ–‡çš„èŒƒå›´ï¼Œä½†æ­£ç¡®é…ç½®çš„ STONITH å¦‚ä¸‹æ‰€ç¤ºã€‚

![stonith](https://vermaden.wordpress.com/wp-content/uploads/2020/09/stonith.jpg?w=960)

# ç¬¬ä¸€ä¸ªæœåŠ¡

ç°åœ¨æˆ‘ä»¬å°†é…ç½®ç¬¬ä¸€ä¸ªé«˜å¯ç”¨æœåŠ¡â€”â€”ç»å…¸ç¤ºä¾‹â€”â€”ä¸€ä¸ªæµ®åŠ¨ IP åœ°å€ :ğŸ™‚:

```sh
root@node1:~ # crm configure primitive IP ocf:heartbeat:IPaddr2 params ip=10.0.10.200 cidr_netmask="24" op monitor interval="30s"
```

è®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„è¿è¡Œæƒ…å†µã€‚

```sh
root@node1:~ # crm configure show
node 1: node1
node 2: node2
node 3: node3
primitive IP IPaddr2 \
        params ip=10.0.10.200 cidr_netmask=24 \
        op monitor interval=30s
property cib-bootstrap-options: \
        have-watchdog=false \
        dc-version=2.0.4-2deceaa3ae \
        cluster-infrastructure=corosync \
        stonith-enabled=false
```

çœ‹èµ·æ¥ä¸é”™â€”â€”æˆ‘ä»¬æ¥æ£€æŸ¥ä¸€ä¸‹é›†ç¾¤çŠ¶æ€ã€‚

```sh
root@node1:~ # crm status
Cluster Summary:
  * Stack: corosync
  * Current DC: node2 (version 2.0.4-2deceaa3ae) - partition with quorum
  * Last updated: Wed Sep  2 22:03:35 2020
  * Last change:  Wed Sep  2 22:02:53 2020 by root via cibadmin on node1
  * 3 nodes configured
  * 1 resource instance configured

Node List:
  * Online: [ node1 node2 node3 ]

Full List of Resources:
  * IP  (ocf::heartbeat:IPaddr2):        Stopped

Failed Resource Actions:
  * IP_monitor_0 on node3 'not installed' (5): call=5, status='complete', exitreason='Setup problem: couldn't find command: ip', last-rc-change='2020-09-02 22:02:53Z', queued=0ms, exec=132ms
  * IP_monitor_0 on node2 'not installed' (5): call=5, status='complete', exitreason='Setup problem: couldn't find command: ip', last-rc-change='2020-09-02 22:02:54Z', queued=0ms, exec=120ms
  * IP_monitor_0 on node1 'not installed' (5): call=5, status='complete', exitreason='Setup problem: couldn't find command: ip', last-rc-change='2020-09-02 22:02:53Z', queued=0ms, exec=110ms
```

ç³Ÿç³•ã€‚Linux æ€ç»´æ¨¡å¼ã€‚ç³»ç»Ÿä¸­é¢„æœŸå­˜åœ¨ **ip(8)** å‘½ä»¤ã€‚ä½†è¿™æ˜¯ FreeBSDï¼Œåƒæ‰€æœ‰ UNIX ç³»ç»Ÿä¸€æ ·ï¼Œå®ƒæä¾›çš„æ˜¯ **ifconfig(8)** å‘½ä»¤ã€‚

æˆ‘ä»¬å¿…é¡»å¦æƒ³åŠæ³•ã€‚ç›®å‰æˆ‘ä»¬å…ˆåˆ é™¤è¿™ä¸ªæ— ç”¨çš„ **IP** æœåŠ¡ã€‚

```sh
root@node1:~ # crm configure delete IP
```

åˆ é™¤åçš„çŠ¶æ€ã€‚

```sh
root@node1:~ # crm status
Cluster Summary:
  * Stack: corosync
  * Current DC: node2 (version 2.0.4-2deceaa3ae) - partition with quorum
  * Last updated: Wed Sep  2 22:04:34 2020
  * Last change:  Wed Sep  2 22:04:31 2020 by root via cibadmin on node1
  * 3 nodes configured
  * 0 resource instances configured

Node List:
  * Online: [ node1 node2 node3 ]

Full List of Resources:
  * No resources
```

# è‡ªå®šä¹‰èµ„æº

è®©æˆ‘ä»¬æŸ¥çœ‹é»˜è®¤ Pacemaker å®‰è£…æä¾›äº†å“ªäº›èµ„æºã€‚

```sh
root@node1:~ # ls -l /usr/local/lib/ocf/resource.d/pacemaker
total 144
-r-xr-xr-x  1 root  wheel   7484 Aug 29 01:22 ClusterMon
-r-xr-xr-x  1 root  wheel   9432 Aug 29 01:22 Dummy
-r-xr-xr-x  1 root  wheel   5256 Aug 29 01:22 HealthCPU
-r-xr-xr-x  1 root  wheel   5342 Aug 29 01:22 HealthIOWait
-r-xr-xr-x  1 root  wheel   9450 Aug 29 01:22 HealthSMART
-r-xr-xr-x  1 root  wheel   6186 Aug 29 01:22 Stateful
-r-xr-xr-x  1 root  wheel  11370 Aug 29 01:22 SysInfo
-r-xr-xr-x  1 root  wheel   5856 Aug 29 01:22 SystemHealth
-r-xr-xr-x  1 root  wheel   7382 Aug 29 01:22 attribute
-r-xr-xr-x  1 root  wheel   7854 Aug 29 01:22 controld
-r-xr-xr-x  1 root  wheel  16134 Aug 29 01:22 ifspeed
-r-xr-xr-x  1 root  wheel  11040 Aug 29 01:22 o2cb
-r-xr-xr-x  1 root  wheel  11696 Aug 29 01:22 ping
-r-xr-xr-x  1 root  wheel   6356 Aug 29 01:22 pingd
-r-xr-xr-x  1 root  wheel   3702 Aug 29 01:22 remote
```

èµ„æºä¸å¤šâ€¦â€¦æˆ‘ä»¬å°†å°è¯•å°† **Dummy** æœåŠ¡ä¿®æ”¹ä¸ºåœ¨ FreeBSD ä¸Šçš„ IP åˆ‡æ¢å™¨ã€‚

```sh
root@node1:~ # cp /usr/local/lib/ocf/resource.d/pacemaker/Dummy /usr/local/lib/ocf/resource.d/pacemaker/ifconfig

root@node1:~ # vi /usr/local/lib/ocf/resource.d/pacemaker/ifconfig
               /* è¾“å…¥é‡çœŸå¤§å•Šâ€¦â€¦ */
```

ç”±äº *WordPress* åšå®¢ç³»ç»Ÿçš„é™åˆ¶ï¼Œæˆ‘ä¸å¾—ä¸å°†è¿™ä¸ª **ifconfig** èµ„æºä»¥å›¾ç‰‡å½¢å¼å‘å¸ƒâ€¦â€¦ä½†åˆ«æ‹…å¿ƒï¼Œæ–‡æœ¬ç‰ˆæœ¬ä¹Ÿå¯åœ¨è¿™é‡Œä¸‹è½½â€”â€”[ifconfig.odt](https://vermaden.wordpress.com/wp-content/uploads/2020/09/ifconfig.odt)ã€‚

æ­¤å¤–ï¼Œç¬¬ä¸€ä¸ªç‰ˆæœ¬çš„æ•ˆæœå¹¶ä¸ç†æƒ³â€¦â€¦

```sh
root@node1:~ # setenv OCF_ROOT /usr/local/lib/ocf
root@node1:~ # ocf-tester -n resourcename /usr/local/lib/ocf/resource.d/pacemaker/ifconfig
Beginning tests for /usr/local/lib/ocf/resource.d/pacemaker/ifconfig...
* rc=3: Your agent has too restrictive permissions: should be 755
-:1: parser error : Start tag expected, '<' not found
usage: /usr/local/lib/ocf/resource.d/pacemaker/ifconfig {start|stop|monitor}
^
* rc=1: Your agent produces meta-data which does not conform to ra-api-1.dtd
* rc=3: Your agent does not support the meta-data action
* rc=3: Your agent does not support the validate-all action
* rc=0: Monitoring a stopped resource should return 7
* rc=0: The initial probe for a stopped resource should return 7 or 5 even if all binaries are missing
* Your agent does not support the notify action (optional)
* Your agent does not support the demote action (optional)
* Your agent does not support the promote action (optional)
* Your agent does not support master/slave (optional)
* rc=0: Monitoring a stopped resource should return 7
* rc=0: Monitoring a stopped resource should return 7
* rc=0: Monitoring a stopped resource should return 7
* Your agent does not support the reload action (optional)
Tests failed: /usr/local/lib/ocf/resource.d/pacemaker/ifconfig failed 9 tests
```

ä½†åœ¨ä¸ºå…¶æ·»åŠ  755 æƒé™å¹¶è¿›è¡Œäº†è‹¥å¹²ï¼ˆä¸Šç™¾æ¬¡ï¼‰ä¿®æ”¹åï¼Œå®ƒç»ˆäºå¯ä»¥ä½¿ç”¨äº†ã€‚

```sh
root@node1:~ # vi /usr/local/lib/ocf/resource.d/pacemaker/ifconfig
             /* LOTS OF NERVOUS TYPING */
root@node1:~ # chmod 755 /usr/local/lib/ocf/resource.d/pacemaker/ifconfig
root@node1:~ # setenv OCF_ROOT /usr/local/lib/ocf
root@node1:~ # ocf-tester -n resourcename /usr/local/lib/ocf/resource.d/pacemaker/ifconfig
Beginning tests for /usr/local/lib/ocf/resource.d/pacemaker/ifconfig...
* Your agent does not support the notify action (optional)
* Your agent does not support the demote action (optional)
* Your agent does not support the promote action (optional)
* Your agent does not support master/slave (optional)
* Your agent does not support the reload action (optional)
/usr/local/lib/ocf/resource.d/pacemaker/ifconfig passed all tests
```

çœ‹èµ·æ¥å¯ä»¥ä½¿ç”¨ã€‚

è¿™æ˜¯ **ifconfig** èµ„æºã€‚ç›®å‰å®ƒç›¸å½“æœ‰é™ï¼Œè€Œä¸” IP åœ°å€æ˜¯ç¡¬ç¼–ç çš„ã€‚

<img width="650" height="1636" alt="image" src="https://github.com/user-attachments/assets/8fd5bab9-9483-48d3-b0b1-efd31f2a6a66" />


è®©æˆ‘ä»¬å°è¯•å‘ FreeBSD é›†ç¾¤æ·»åŠ æ–°çš„ **IP** èµ„æºã€‚

# æµ‹è¯•

```
root@node1:~ # crm configure primitive IP ocf:pacemaker:ifconfig op monitor interval="30"
```

å·²æ·»åŠ ã€‚

æˆ‘ä»¬æ¥çœ‹ç°åœ¨ **status** å‘½ä»¤æ˜¾ç¤ºçš„æƒ…å†µã€‚

```sh
root@node1:~ # crm status
Cluster Summary:
  * Stack: corosync
  * Current DC: node2 (version 2.0.4-2deceaa3ae) - partition with quorum
  * Last updated: Wed Sep  2 22:44:52 2020
  * Last change:  Wed Sep  2 22:44:44 2020 by root via cibadmin on node1
  * 3 nodes configured
  * 1 resource instance configured

Node List:
  * Online: [ node1 node2 node3 ]

Full List of Resources:
  * IP  (ocf::pacemaker:ifconfig):       Started node1

Failed Resource Actions:
  * IP_monitor_0 on node3 'not installed' (5): call=24, status='Not installed', exitreason='', last-rc-change='2020-09-02 22:42:52Z', queued=0ms, exec=5ms
  * IP_monitor_0 on node2 'not installed' (5): call=24, status='Not installed', exitreason='', last-rc-change='2020-09-02 22:42:53Z', queued=0ms, exec=2ms
```

ç³Ÿç³•ï¼Œæˆ‘å¿˜äº†å°†è¿™ä¸ªæ–°çš„ **ifconfig** èµ„æºå¤åˆ¶åˆ°å…¶ä»–èŠ‚ç‚¹ã€‚ç°åœ¨æ¥ä¿®å¤å®ƒã€‚

```sh
root@node1:~ # rsync -av /usr/local/lib/ocf/resource.d/pacemaker/ node2:/usr/local/lib/ocf/resource.d/pacemaker/
Password for root@node2:
sending incremental file list
./
ifconfig

sent 3,798 bytes  received 38 bytes  1,534.40 bytes/sec
total size is 128,003  speedup is 33.37

root@node1:~ # rsync -av /usr/local/lib/ocf/resource.d/pacemaker/ node3:/usr/local/lib/ocf/resource.d/pacemaker/
Password for root@node3:
sending incremental file list
./
ifconfig

sent 3,798 bytes  received 38 bytes  1,534.40 bytes/sec
total size is 128,003  speedup is 33.37
```

ç°åœ¨æˆ‘ä»¬å…ˆåœæ­¢ã€åˆ é™¤ï¼Œç„¶åé‡æ–°æ·»åŠ è¿™ä¸ªé‡è¦çš„èµ„æºã€‚

```sh
root@node1:~ # crm resource stop IP
root@node1:~ # crm configure delete IP
root@node1:~ # crm configure primitive IP ocf:pacemaker:ifconfig op monitor interval="30"
```

ç¥ˆç¥·é¡ºåˆ©å§ã€‚

```sh
root@node1:~ # crm status
Cluster Summary:
  * Stack: corosync
  * Current DC: node2 (version 2.0.4-2deceaa3ae) - partition with quorum
  * Last updated: Wed Sep  2 22:45:46 2020
  * Last change:  Wed Sep  2 22:45:43 2020 by root via cibadmin on node1
  * 3 nodes configured
  * 1 resource instance configured

Node List:
  * Online: [ node1 node2 node3 ]

Full List of Resources:
  * IP  (ocf::pacemaker:ifconfig):       Started node1
```

çœ‹èµ·æ¥è¿è¡Œæ­£å¸¸ã€‚

è®©æˆ‘ä»¬éªŒè¯å®ƒæ˜¯å¦ç¡®å®åœ¨åº”è¯¥çš„èŠ‚ç‚¹ä¸Šå¯åŠ¨ã€‚

```sh
root@node1:~ # ifconfig em0
em0: flags=8843 metric 0 mtu 1500
        options=81009b
        ether 08:00:27:2a:78:60
        inet 10.0.10.111 netmask 0xffffff00 broadcast 10.0.10.255
        inet 10.0.10.200 netmask 0xffffff00 broadcast 10.0.10.255
        media: Ethernet autoselect (1000baseT )
        status: active
        nd6 options=29

root@node2:~ # ifconfig em0
em0: flags=8843 metric 0 mtu 1500
        options=81009b
        ether 08:00:27:80:50:05
        inet 10.0.10.112 netmask 0xffffff00 broadcast 10.0.10.255
        media: Ethernet autoselect (1000baseT )
        status: active
        nd6 options=29

root@node3:~ # ifconfig em0
em0: flags=8843 metric 0 mtu 1500
        options=81009b
        ether 08:00:27:74:5e:b9
        inet 10.0.10.113 netmask 0xffffff00 broadcast 10.0.10.255
        media: Ethernet autoselect (1000baseT )
        status: active
        nd6 options=29
```

çœ‹èµ·æ¥ç¡®å®åœ¨å·¥ä½œã€‚

ç°åœ¨æˆ‘ä»¬å°è¯•å°†å®ƒç§»åŠ¨åˆ°é›†ç¾¤ä¸­çš„å¦ä¸€å°èŠ‚ç‚¹ã€‚

```sh
root@node1:~ # crm resource move IP node3
INFO: Move constraint created for IP to node3

root@node1:~ # crm status
Cluster Summary:
  * Stack: corosync
  * Current DC: node2 (version 2.0.4-2deceaa3ae) - partition with quorum
  * Last updated: Wed Sep  2 22:47:31 2020
  * Last change:  Wed Sep  2 22:47:28 2020 by root via crm_resource on node1
  * 3 nodes configured
  * 1 resource instance configured

Node List:
  * Online: [ node1 node2 node3 ]

Full List of Resources:
  * IP  (ocf::pacemaker:ifconfig):       Started node3
```

å·²æˆåŠŸåˆ‡æ¢åˆ° **node3** ç³»ç»Ÿã€‚

```sh
root@node3:~ # ifconfig em0
em0: flags=8843 metric 0 mtu 1500
        options=81009b
        ether 08:00:27:74:5e:b9
        inet 10.0.10.113 netmask 0xffffff00 broadcast 10.0.10.255
        inet 10.0.10.200 netmask 0xffffff00 broadcast 10.0.10.255
        media: Ethernet autoselect (1000baseT )
        status: active
        nd6 options=29

root@node1:~ # ifconfig em0
em0: flags=8843 metric 0 mtu 1500
        options=81009b
        ether 08:00:27:2a:78:60
        inet 10.0.10.111 netmask 0xffffff00 broadcast 10.0.10.255
        media: Ethernet autoselect (1000baseT )
        status: active
        nd6 options=29
```

ç°åœ¨æˆ‘ä»¬å°† **å…³é—­** **node3** ç³»ç»Ÿï¼Œä»¥æ£€æŸ¥è¿™ä¸ª **IP** æ˜¯å¦çœŸçš„å…·å¤‡é«˜å¯ç”¨æ€§ã€‚

```sh
root@node2:~ # crm status
Cluster Summary:
  * Stack: corosync
  * Current DC: node2 (version 2.0.4-2deceaa3ae) - partition with quorum
  * Last updated: Wed Sep  2 22:49:57 2020
  * Last change:  Wed Sep  2 22:47:29 2020 by root via crm_resource on node1
  * 3 nodes configured
  * 1 resource instance configured

Node List:
  * Online: [ node1 node2 node3 ]

Full List of Resources:
  * IP  (ocf::pacemaker:ifconfig):       Started node3

root@node3:~ # poweroff

root@node2:~ # crm status
Cluster Summary:
  * Stack: corosync
  * Current DC: node2 (version 2.0.4-2deceaa3ae) - partition with quorum
  * Last updated: Wed Sep  2 22:50:16 2020
  * Last change:  Wed Sep  2 22:47:29 2020 by root via crm_resource on node1
  * 3 nodes configured
  * 1 resource instance configured

Node List:
  * Online: [ node1 node2 ]
  * OFFLINE: [ node3 ]

Full List of Resources:
  * IP  (ocf::pacemaker:ifconfig):       Started node1
```

çœ‹èµ·æ¥æ•…éšœåˆ‡æ¢è¿›è¡Œå¾—å¾ˆé¡ºåˆ©ã€‚

**crm** å‘½ä»¤è¿˜ä¼šå¯¹å…¶è¾“å‡ºçš„ä¸åŒéƒ¨åˆ†è¿›è¡Œé«˜äº®æ˜¾ç¤ºã€‚

![failover](https://vermaden.wordpress.com/wp-content/uploads/2020/09/failover.jpg?w=960)

å¾ˆé«˜å…´çŸ¥é“ Pacemaker å’Œ Corosync é›†ç¾¤åœ¨ FreeBSD ä¸Šè¿è¡Œè‰¯å¥½ã€‚

è™½ç„¶éœ€è¦ä¸€äº›å·¥ä½œæ¥ç¼–å†™å¿…è¦çš„èµ„æºæ–‡ä»¶ï¼Œä½†åªè¦æœ‰æ—¶é—´å’Œå†³å¿ƒï¼Œå®Œå…¨å¯ä»¥å°† FreeBSD æ‰“é€ æˆä¸€ä¸ªéå¸¸å¼ºå¤§çš„é«˜å¯ç”¨é›†ç¾¤ã€‚


